{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Github ECG",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrizfJg3sLmM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('path')\n",
        "drive.mount('path')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-81n65Us8sL"
      },
      "source": [
        "pip install patool   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2JBYMBQuuyk"
      },
      "source": [
        "import patoolib\n",
        "patoolib.extract_archive('src',outdir='/dest')\n",
        "patoolib.extract_archive('src',outdir='/dest')\n",
        "patoolib.extract_archive('src',outdir='/dest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxV_PVjHtEhp"
      },
      "source": [
        "\"\"\"\n",
        "Data preprocessing\n",
        "The available data is in csv file\n",
        "For training the Model, the csv data is converted to image, and reshaped to (256,256,3)\n",
        "\"\"\"\n",
        "import glob\n",
        "import scipy.misc\n",
        "from numpy import genfromtxt                                                               \n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "from skimage.transform import resize\n",
        "import os\n",
        "from google.colab import drive, files\n",
        "from io import BytesIO\n",
        "\n",
        "if not os.path.exists('imgs4'):\n",
        "  os.mkdir('imgs4')\n",
        "\n",
        "for filepath in glob.iglob('path/*.csv'):\n",
        "    img_array = genfromtxt(filepath, delimiter=',')\n",
        "    im = Image.fromarray(img_array)\n",
        "    img = np.repeat(img_array[:, :, np.newaxis], 3, axis=2)\n",
        "    img = resize(img, (256, 256, 3))\n",
        "    img = ((img * 255).astype(np.uint8))\n",
        "    img = Image.fromarray(img.astype(np.uint8))\n",
        "    img.save(\"imgs4/check\"+str(n)+\".jpeg\", \"JPEG\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94xlgEye7qq7"
      },
      "source": [
        "\"\"\"\n",
        "Required imports for fetching data, plotting results, and building the model\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout,BatchNormalization,Activation,MaxPooling2D\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from  tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlAlJTgw-QBi"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/path/train',\n",
        "        target_size=(256,256),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        '/path/test',\n",
        "        target_size=(256,256),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEsFgqZG-X2Y"
      },
      "source": [
        "\"\"\"\n",
        "Base Model is taken as Mobilenet V2\n",
        "For classification task of 6 classes of Myocardial Infraction, the last layer\n",
        "was modified to Dense(6)\n",
        "\"\"\"\n",
        "import keras\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D,Dropout\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(256, 256, 3))\n",
        "\n",
        "base_model =MobileNetV2(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x=Dropout(0.5)(x)\n",
        "predictions = Dense(6, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZMBdwwRng0l"
      },
      "source": [
        "\"\"\"\n",
        "Training last 20 layers yielded better\n",
        "\"\"\"\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "for layer in model.layers[130:]:\n",
        "   layer.trainable = True\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtebZBM5dQfG"
      },
      "source": [
        "\"\"\"\n",
        "Callbacks for the model\n",
        "\"\"\"\n",
        "def scheduler(epochs, lr):\n",
        "  if epochs < 5:\n",
        "    return lr                                                     \n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.01)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "      monitor='val_loss',\n",
        "        factor=0.2,\n",
        "        patience=5,\n",
        "        verbose=0,\n",
        "        min_lr=0.01\n",
        "    )\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1)\n",
        "tensorboard=tf.keras.callbacks.TensorBoard(\n",
        "    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,\n",
        "    update_freq='epoch', profile_batch=2, embeddings_freq=0,\n",
        "    embeddings_metadata=None\n",
        ")\n",
        "learning_scheduler=tf.keras.callbacks.LearningRateScheduler(\n",
        "    scheduler, verbose=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtn6K7Hf-c5W"
      },
      "source": [
        "\"\"\"\n",
        "Model fitting\n",
        "\"\"\"\n",
        "\n",
        "epochs=50\n",
        "nb_train_samples=3435\n",
        "nb_validation_samples=935\n",
        "\n",
        "history=model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=int(nb_train_samples / batch_size),\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=int(nb_validation_samples / batch_size),\n",
        "    callbacks=[reduce_lr,learning_scheduler])\n",
        "    \n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GVaYiaezUkO"
      },
      "source": [
        "\"\"\"\n",
        "Model score evaluation\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "Y_pred = model.predict_generator(validation_generator, nb_validation_samples // batch_size+1,verbose=True)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "y_true = validation_generator.labels                                  \n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_true, y_pred))\n",
        "print('Classification Report')\n",
        "target_names = ['ALMI','AMI','ASMI','IMI','INFERIOR','NORMAL'] \n",
        "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X-lFg0XkuFi"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X='path'\n",
        "X_train, X_test = train_test_split(X, test_size = 0.3, random_state = 0)\n",
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8aKXmS_zHDs"
      },
      "source": [
        "ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWHb0C2J28LE"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
        "\n",
        "# helper function for plotting roc auc score\n",
        "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
        "    lb = LabelBinarizer()\n",
        "    lb.fit(y_test)\n",
        "    y_test = lb.transform(y_test)\n",
        "    y_pred = lb.transform(y_pred)\n",
        "\n",
        "    for (idx, c_label) in enumerate(target_names): \n",
        "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
        "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='orange', label='ALMI')\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='green', label='AMI')\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='red', label='ASMI')\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='pink', label='IMI')\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='blue', label='INFERIOR')\n",
        "        c_ax.plot(fpr, tpr, 'b-', linestyle='--',color='grey', label='NORMAL')\n",
        "\n",
        "    return roc_auc_score(y_test, y_pred, average=average)\n",
        "\n",
        "\n",
        "validation_generator.reset()\n",
        "y_pred = model.predict_generator(validation_generator, verbose = True)\n",
        "y_max = np.argmax(y_pred, axis=1)\n",
        "multiclass_roc_auc_score(validation_generator.classes, y_max)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHab8F54zKC3"
      },
      "source": [
        "KFOLD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJ2-arNHoGE"
      },
      "source": [
        "\"\"\"\n",
        "KFOLD cross validation was applied for 5 folds\n",
        "for each iteration the model is trained and validated with data it hasn't come\n",
        "across in previous iterations\n",
        "the rng can be seeded to have controlled randomness\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# uncomment following 2 lines to have a controlled rng\n",
        "# seed = 7\n",
        "# np.random.seed(seed)\n",
        "data_x = []\n",
        "data_y = []\n",
        "\n",
        "path = 'path'\n",
        "classname = 0\n",
        "# loading image data\n",
        "for folder in os.listdir(path):\n",
        "    labels = [0. for _ in range(6)]\n",
        "    labels = np.array(labels)\n",
        "    for image in os.listdir(os.path.join(path, folder)):\n",
        "        image_path = os.path.join(path, folder, image)\n",
        "        img = keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
        "        img_array = keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = img_array/255.0\n",
        "        data_x.append(img_array)\n",
        "        labels[classname] = 1.\n",
        "        data_y.append(labels)\n",
        "    classname += 1\n",
        "\n",
        "data_x, data_y = np.array(data_x), np.array(data_y)\n",
        "data_x, data_y = shuffle(data_x, data_y, random_state=seed)\n",
        "\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "hists = []\n",
        "\n",
        "# fitting / evaluating the model on the 5 folds\n",
        "for train, test in kfold.split(data_x, data_y):\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    test_x = []\n",
        "    test_y = []\n",
        "    for x in train:\n",
        "        train_x.append(data_x[x])\n",
        "        train_y.append(data_y[x])\n",
        "    for x in test:\n",
        "        test_x.append(data_x[x])\n",
        "        test_y.append(data_y[x])\n",
        "\n",
        "    train_x, train_y, test_x, test_y = np.array(train_x), np.array(train_y), np.array(test_x), np.array(test_y)\n",
        "    model = keras.models.load_model('base_mobilenet.h5')\n",
        "    model.compile(Adam(lr=0.0001), 'categorical_crossentropy',  metrics=['accuracy'])\n",
        "    history = model.fit(train_x, train_y, validation_split=0.2, epochs=30, batch_size=128, verbose=2)\n",
        "    hists.append(history)\n",
        "    scores = model.evaluate(test_x, test_y, verbose = 0)\n",
        "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "    cvscores.append(scores[1] * 100)\n",
        "\n",
        "    \n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "\n",
        "model.save('kfold_mobilenet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMthQNXrDrcZ"
      },
      "source": [
        "\"\"\"\n",
        "Plots for Kfold cross validation\n",
        "\"\"\"\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(nrows=len(hists), ncols=2, figsize=(20,20))\n",
        "\n",
        "for i, history in enumerate(hists):\n",
        "    history = history.history\n",
        "    ax[i, 0].plot(history['accuracy'], label='Accuracy')\n",
        "    ax[i, 0].plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "    ax[i, 0].legend(loc='upper left')\n",
        "    ax[i, 0].set_title('Accuracy')\n",
        "    ax[i, 1].plot(history['loss'], label='Loss')\n",
        "    ax[i, 1].plot(history['val_loss'], label='Validation Loss')\n",
        "    ax[i, 1].legend(loc='upper left')\n",
        "    ax[i, 1].set_title('Loss')\n",
        "    plt.xlabel('Epochs')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}